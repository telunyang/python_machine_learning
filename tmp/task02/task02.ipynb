{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn xgboost pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc099b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c80488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"目前 GPU 代號: \" + str(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"不支援 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f795cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "https://www.kaggle.com/code/stuarthallows/using-xgboost-with-scikit-learn/notebook\n",
    "https://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6ebc0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "全域設定\n",
    "'''\n",
    "# {'n_estimators': 633, 'max_depth': None, 'learning_rate': 0.05, 'colsample_bytree': 0.99}\n",
    "\n",
    "# 分類器初始化\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "#     objective = 'multi:softprob',\n",
    "    tree_method = 'gpu_hist', \n",
    "    gpu_id = 0,\n",
    "    n_estimators = 633,\n",
    "    max_depth = None,\n",
    "    learning_rate = 0.05,\n",
    "    colsample_bytree = 0.99\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "主要函式\n",
    "'''\n",
    "# 切割資料\n",
    "def split_data():\n",
    "    try:\n",
    "        # 取得訓練資料\n",
    "        df = pd.read_csv('./train_dec04_task2.csv')\n",
    "        X = df.iloc[:,:7].values\n",
    "        y = df['class'].values\n",
    "        \n",
    "        # 將 label 的順序，從文字轉成數字格式\n",
    "        Ly = LabelEncoder()\n",
    "        y = Ly.fit_transform(y)\n",
    "        print(y)\n",
    "        print(Ly.classes_)\n",
    "        \n",
    "        # 切割資料\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        \n",
    "        # 回傳切割結果\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "        \n",
    "# 訓練切割後的資料，並儲存模型\n",
    "def train(X_train, X_test, y_train, y_test):\n",
    "    global xgb_model\n",
    "    \n",
    "    try:  \n",
    "        # 訓練模型\n",
    "        xgb_model.fit(X_train, y_train, eval_metric=\"mlogloss\", early_stopping_rounds=10, eval_set=[(X_test, y_test)])\n",
    "        \n",
    "        # 預測結果\n",
    "        y_pred = xgb_model.predict(X_test)\n",
    "        \n",
    "        # 儲存 model\n",
    "        xgb_model.save_model(\"task02_model.json\")\n",
    "        \n",
    "        # 回傳 model 跟 測試資料的預測結果\n",
    "        return xgb_model, y_pred\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "\n",
    "# 訓練全部資料(不切割)，並儲存模型\n",
    "def train_all():\n",
    "    global xgb_model\n",
    "    \n",
    "    try:\n",
    "        # 取得訓練資料\n",
    "        df = pd.read_csv('./train_dec04_task2.csv')\n",
    "        X = df.iloc[:,:7].values\n",
    "        y = df['class'].values\n",
    "        \n",
    "        # 將 label 的順序，從文字轉成數字格式\n",
    "        Ly = LabelEncoder()\n",
    "        y = Ly.fit_transform(y)\n",
    "        \n",
    "        # 訓練模型\n",
    "        xgb_model.fit(X, y)\n",
    "        \n",
    "        # 儲存 model\n",
    "        xgb_model.save_model(\"task02_model.json\")\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "        \n",
    "# 預測結果\n",
    "def predict():\n",
    "    global xgb_model\n",
    "    \n",
    "    try:\n",
    "        # 讀取模型\n",
    "        xgb_model.load_model(\"task02_model.json\")\n",
    "        \n",
    "        # 讀取測試集\n",
    "        df = pd.read_csv('./test_dec04_task2_only_features.csv')\n",
    "        X = df.iloc[:,:7].values\n",
    "        \n",
    "        # 進行預測\n",
    "        y_pred = xgb_model.predict(X)\n",
    "        \n",
    "        # 建立 submission 資料\n",
    "        dict_headers = {\n",
    "            \"Id\": [(x + 1) for x in range(len(y_pred))],\n",
    "            \"Category\": y_pred\n",
    "        }\n",
    "        \n",
    "        # 將 dict 轉成 dataframe，並檢視結果\n",
    "        df = pd.DataFrame(dict_headers)\n",
    "        df['Category'] = df['Category'].replace([0], 'A')\n",
    "        df['Category'] = df['Category'].replace([1], 'B')\n",
    "        df['Category'] = df['Category'].replace([2], 'C')\n",
    "        print(df)\n",
    "        \n",
    "        # 儲存成 csv，以便上傳結果至 kaggle\n",
    "        df.to_csv('submission_task02.csv', index=False)\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "        \n",
    "        \n",
    "'''\n",
    "檢視設定與結果\n",
    "'''\n",
    "# 取得最佳參數\n",
    "def show_best_params(X_train, y_train):\n",
    "    try:\n",
    "        # 分類器初始化\n",
    "        xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "        \n",
    "        # 參數範圍初始化\n",
    "        n_estimators = [int(x) for x in np.linspace(start=10, stop=2000, num=100)]\n",
    "        max_depth = [int(x) for x in np.linspace(start=10, stop=110, num=11)]\n",
    "        max_depth.append(None)\n",
    "        learning_rate=[round(float(x),2) for x in np.linspace(start=0.01, stop=0.2, num=100)]\n",
    "        colsample_bytree =[round(float(x),2) for x in np.linspace(start=0.1, stop=1, num=100)]\n",
    "        \n",
    "        # 尋找合適參與的資料格式\n",
    "        random_grid = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'learning_rate': learning_rate,\n",
    "            'colsample_bytree': colsample_bytree\n",
    "        }\n",
    "        \n",
    "        # 透過交叉驗證來取得參數\n",
    "        xg_random = RandomizedSearchCV(\n",
    "            estimator = xgb_model, \n",
    "            param_distributions = random_grid, \n",
    "            n_iter = 100, \n",
    "            cv = 3, \n",
    "            verbose = 2, \n",
    "            random_state = 42, \n",
    "            n_jobs = -1\n",
    "        )\n",
    "        \n",
    "        # 透過訓練來尋找合適參數組合\n",
    "        xg_random.fit(X_train, y_train)\n",
    "        \n",
    "        print(xg_random.best_params_)\n",
    "        \n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "\n",
    "# 計算各項評估分數\n",
    "def show_scores(m, x_train, x_test, y_train, y_test, train=True):\n",
    "    try:\n",
    "        if train: # 計算 使用訓練資料 的評估結果\n",
    "            pred = m.predict(x_train)\n",
    "            print('Train Result:')\n",
    "            print(f\"- Accuracy Score: {accuracy_score(y_train, pred)*100:.2f}%\")\n",
    "            print(f\"- Precision Score: {precision_score(y_train, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"- Recall Score: {recall_score(y_train, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"- F1 score: {f1_score(y_train, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"Confusion Matrix:\\n {confusion_matrix(y_train, pred)}\")\n",
    "            print()\n",
    "        elif train == False: # 計算 使用測試資料 的評估結果\n",
    "            pred = m.predict(x_test)\n",
    "            print('Test Result:')\n",
    "            print(f\"- Accuracy Score: {accuracy_score(y_test, pred)*100:.2f}%\")\n",
    "            print(f\"- Precision Score: {precision_score(y_test, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"- Recall Score: {recall_score(y_test, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"- F1 score: {f1_score(y_test, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, pred)}\")\n",
    "            print()\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "    \n",
    "# 顯示特徵重要性\n",
    "def show_feature_importance(xgb_model):\n",
    "    try:\n",
    "        plot_importance(xgb_model)\n",
    "        print('特徵重要程度: ' + xgb_model.feature_importances_)\n",
    "    except Exception as err:\n",
    "        print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "主程式 - 尋找合適的參數\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 切割資料\n",
    "        X_train, X_test, y_train, y_test = split_data()\n",
    "\n",
    "        # 取得最佳參數\n",
    "        show_best_params(X_train, y_train)\n",
    "    except Exception as err:\n",
    "        print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c75bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "主程式 - 訓練 和 檢視結果，並儲存 model\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 切割資料\n",
    "        X_train, X_test, y_train, y_test = split_data()\n",
    "\n",
    "        # 訓練模型，並取得測試資料預測結果\n",
    "        xgb_model, y_pred = train(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        # 輸出評估結果\n",
    "        print(f\"best score: {xgb_model.best_score}, best iteration: {xgb_model.best_iteration}, best ntree limit {xgb_model.best_ntree_limit}\")\n",
    "        show_scores(xgb_model, X_train, X_test, y_train, y_test, train=True)\n",
    "        show_scores(xgb_model, X_train, X_test, y_train, y_test, train=False)\n",
    "        show_feature_importance(xgb_model)\n",
    "    except Exception as err:\n",
    "        print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "主程式 - 訓練完整的訓練資料(不評估模型)，並儲存 model\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        train_all()\n",
    "    except Exception as err:\n",
    "        print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd908f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "主程式 - 預測結果 與 儲存 submission 用的 csv\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 讀取官方所提供的無 label 特徵資料 (test data)，預測結果 (類別) 並儲存成 csv\n",
    "        predict()\n",
    "    except Exception as err:\n",
    "        print(str(err))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_jupyter",
   "language": "python",
   "name": "ml_for_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
