{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847e212",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn xgboost pandas numpy imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc099b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c80488",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"目前 GPU 代號: \" + str(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"不支援 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f795cd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "https://www.kaggle.com/code/stuarthallows/using-xgboost-with-scikit-learn/notebook\n",
    "https://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html\n",
    "https://scikit-learn.org/stable/modules/impute.html\n",
    "'''\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from pprint import pprint\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6ebc0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "筆記:\n",
    "weights = total_samples / (n_classes * class_samples * 1.0)\n",
    "\n",
    "A類別權重 = 6500 / (4 * 1000 * 1.0) = 6500 / 4000 = 1.625\n",
    "B類別權重 = 6500 / (4 * 2000 * 1.0) = 6500 / 8000 = 0.8125\n",
    "C類別權重 = 6500 / (4 * 2500 * 1.0) = 6500 / 10000 = 0.65\n",
    "D類別權重 = 6500 / (4 * 1000 * 1.0) = 6500 / 4000 = 1.625\n",
    "'''\n",
    "\n",
    "'''\n",
    "全域設定\n",
    "'''\n",
    "# 分類器初始化，設定模型參數\n",
    "'''\n",
    "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
    "{'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.16, 'colsample_bytree': 0.5}\n",
    "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
    "{'n_estimators': 30, 'max_depth': None, 'learning_rate': 0.03, 'colsample_bytree': 0.8}\n",
    "{'n_estimators': 180, 'max_depth': 70, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
    "{'n_estimators': 120, 'max_depth': 80, 'learning_rate': 0.18, 'colsample_bytree': 0.9}\n",
    "Fitting 20 folds for each of 300 candidates, totalling 6000 fits\n",
    "{'n_estimators': 150, 'max_depth': 70, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
    "{'n_estimators': 180, 'max_depth': 70, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
    "'''\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective = 'multi:softprob',\n",
    "    n_estimators = 180,\n",
    "    max_depth = 70,\n",
    "    learning_rate = 0.2,\n",
    "    colsample_bytree = 1.0,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "主要函式\n",
    "'''\n",
    "# 切割資料\n",
    "def split_data():\n",
    "    try:\n",
    "        # 取得訓練資料\n",
    "        df = pd.read_csv('./train_dec08_task3.csv')\n",
    "        X = df.iloc[:, [6,0,2,5,4,3,1]].values # :14\n",
    "        y = df['class'].values\n",
    "        \n",
    "        # 將 label 的順序，從文字轉成數字格式\n",
    "        Ly = LabelEncoder()\n",
    "        y = Ly.fit_transform(y)\n",
    "        print(y)\n",
    "        print(Ly.classes_)\n",
    "        \n",
    "        # 切割資料\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "\n",
    "        # 過取樣 (Over-sampling)\n",
    "        X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "        print(X_train.shape)\n",
    "        \n",
    "        # 欠取樣 (Under-sampling)\n",
    "        X_train, y_train = TomekLinks().fit_resample(X_train, y_train)\n",
    "        print(X_train.shape)\n",
    "        \n",
    "        # 回傳切割結果\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "        \n",
    "# 訓練切割後的資料，並儲存模型\n",
    "def train(X_train, X_test, y_train, y_test):\n",
    "    global xgb_model\n",
    "    \n",
    "    try:\n",
    "        # 訓練模型\n",
    "        xgb_model.fit(\n",
    "            X_train, \n",
    "            y_train, \n",
    "            eval_metric=\"mlogloss\", \n",
    "            early_stopping_rounds=10, \n",
    "            eval_set=[(X_test, y_test)],\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "#         selection = SelectFromModel(xgb_model, prefit=True)\n",
    "#         select_X_train = selection.transform(X_train)\n",
    "#         print(selection.feature_names_in_)\n",
    "        \n",
    "#         # 預測結果\n",
    "#         selection_model = xgb.XGBClassifier()\n",
    "#         selection_model.fit(select_X_train, y_train)\n",
    "#         select_X_test = selection.transform(X_test)\n",
    "\n",
    "#         y_pred = selection_model.predict(select_X_test)\n",
    "        y_pred = xgb_model.predict(X_test)\n",
    "        \n",
    "        # 儲存 model\n",
    "        xgb_model.save_model(\"task03_model.json\")\n",
    "        \n",
    "        # 回傳 model 跟 測試資料的預測結果\n",
    "        return xgb_model, y_pred\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "        \n",
    "# 預測結果\n",
    "def predict():\n",
    "    global xgb_model\n",
    "    \n",
    "    try:\n",
    "        # 讀取模型\n",
    "        xgb_model.load_model(\"task03_model.json\")\n",
    "        \n",
    "        # 讀取測試集\n",
    "        df = pd.read_csv('./test_dec08_task3_only_features.csv')\n",
    "        X = df.iloc[:, [6,0,2,5,4,3,1]].values #:14\n",
    "        \n",
    "        # 進行預測\n",
    "        y_pred = xgb_model.predict(X)\n",
    "        \n",
    "        # 建立 submission 資料\n",
    "        dict_headers = {\n",
    "            \"Id\": [(x + 1) for x in range(len(y_pred))],\n",
    "            \"Category\": y_pred\n",
    "        }\n",
    "        \n",
    "        # 將 dict 轉成 dataframe，並檢視結果\n",
    "        df = pd.DataFrame(dict_headers)\n",
    "        df['Category'] = df['Category'].replace([0], 'A')\n",
    "        df['Category'] = df['Category'].replace([1], 'B')\n",
    "        df['Category'] = df['Category'].replace([2], 'C')\n",
    "        df['Category'] = df['Category'].replace([3], 'D')\n",
    "        print(df)\n",
    "        \n",
    "        # 儲存成 csv，以便上傳結果至 kaggle\n",
    "        df.to_csv('submission_task03.csv', index=False)\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "        \n",
    "        \n",
    "'''\n",
    "檢視設定與結果\n",
    "'''\n",
    "# 取得最佳參數\n",
    "def show_best_params(X_train, y_train):\n",
    "    try:\n",
    "        # 分類器初始化\n",
    "        xgb_model = xgb.XGBClassifier(random_state = 42)\n",
    "        \n",
    "        # 參數範圍初始化\n",
    "        n_estimators = [int(x) for x in np.linspace(start=10, stop=200, num=20)]\n",
    "        max_depth = [int(x) for x in np.linspace(start=10, stop=110, num=11)]\n",
    "        max_depth.append(None)\n",
    "        learning_rate=[round(float(x),2) for x in np.linspace(start=0.01, stop=0.2, num=10)]\n",
    "        colsample_bytree =[round(float(x),2) for x in np.linspace(start=0.1, stop=1, num=10)]\n",
    "        \n",
    "        # 尋找合適參與的資料格式\n",
    "        random_grid = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'learning_rate': learning_rate,\n",
    "            'colsample_bytree': colsample_bytree\n",
    "        }\n",
    "        \n",
    "        # 透過交叉驗證來取得參數\n",
    "        xg_random = RandomizedSearchCV(\n",
    "            estimator = xgb_model, \n",
    "            param_distributions = random_grid, \n",
    "            n_iter = 100, \n",
    "            cv = 10, \n",
    "            verbose = 3, \n",
    "            random_state = 42, \n",
    "            n_jobs = -1\n",
    "        )\n",
    "        \n",
    "        # 透過訓練來尋找合適參數組合\n",
    "        xg_random.fit(X_train, y_train)\n",
    "        \n",
    "        print(xg_random.best_params_)\n",
    "        \n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "\n",
    "# 計算各項評估分數\n",
    "def show_scores(m, x_train, x_test, y_train, y_test, train=True):\n",
    "    try:\n",
    "        if train: # 計算 使用訓練資料 的評估結果\n",
    "            pred = m.predict(x_train)\n",
    "            print('Train Result:')\n",
    "            print(f\"- Accuracy Score: {accuracy_score(y_train, pred)*100:.2f}%\")\n",
    "            print(f\"- Precision Score: {precision_score(y_train, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"- Recall Score: {recall_score(y_train, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"- F1 score: {f1_score(y_train, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"Confusion Matrix:\\n {confusion_matrix(y_train, pred)}\")\n",
    "            print()\n",
    "        elif train == False: # 計算 使用測試資料 的評估結果\n",
    "            pred = m.predict(x_test)\n",
    "            print('Test Result:')\n",
    "            print(f\"- Accuracy Score: {accuracy_score(y_test, pred)*100:.2f}%\")\n",
    "            print(f\"- Precision Score: {precision_score(y_test, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"- Recall Score: {recall_score(y_test, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"- F1 score: {f1_score(y_test, pred, average='micro')*100:.2f}%\")\n",
    "            print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, pred)}\")\n",
    "            print()\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "    \n",
    "# 顯示特徵重要性\n",
    "def show_feature_importance(xgb_model):\n",
    "    try:\n",
    "        plot_importance(xgb_model)\n",
    "        print('特徵重要程度: ' + xgb_model.feature_importances_)\n",
    "    except Exception as err:\n",
    "        print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab75d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "主程式 - 尋找合適的參數\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 切割資料\n",
    "        X_train, X_test, y_train, y_test = split_data()\n",
    "\n",
    "        # 取得最佳參數\n",
    "        show_best_params(X_train, y_train)\n",
    "    except Exception as err:\n",
    "        print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c75bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "主程式 - 訓練 和 檢視結果，並儲存 model\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 切割資料\n",
    "        X_train, X_test, y_train, y_test = split_data()\n",
    "\n",
    "        # 訓練模型，並取得測試資料預測結果\n",
    "        model, y_pred = train(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        # 輸出評估結果\n",
    "        print(f\"best score: {model.best_score}, best iteration: {model.best_iteration}, best ntree limit {model.best_ntree_limit}\")\n",
    "        show_scores(model, X_train, X_test, y_train, y_test, train=True)\n",
    "        show_scores(model, X_train, X_test, y_train, y_test, train=False)\n",
    "        show_feature_importance(model)\n",
    "    except Exception as err:\n",
    "        print(str(err)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb19ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "主程式 - 訓練完整的訓練資料(不評估模型)，並儲存 model\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        train_all()\n",
    "    except Exception as err:\n",
    "        print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd908f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "主程式 - 預測結果 與 儲存 submission 用的 csv\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 讀取官方所提供的無 label 特徵資料 (test data)，預測結果 (類別) 並儲存成 csv\n",
    "        predict()\n",
    "    except Exception as err:\n",
    "        print(str(err))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_jupyter",
   "language": "python",
   "name": "ml_for_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
